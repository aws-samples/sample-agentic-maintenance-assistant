#!/usr/bin/env python3
"""
Generate all ML models required by the agentic maintenance assistant
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib
import os

def generate_anomaly_detector():
    """Generate anomaly_detector.pkl and scaler.pkl"""
    print("Generating Anomaly Detector...")
    
    # Load baseline data
    baseline_data = pd.read_csv('vibration_data.csv')
    
    # Initialize models
    scaler = StandardScaler()
    anomaly_model = IsolationForest(contamination=0.1, random_state=42)
    
    # Generate training features
    training_features = []
    for i in range(50):
        # Add variations to simulate normal rides
        simulated_ride = baseline_data.copy()
        simulated_ride['accel_x'] += np.random.normal(0, 0.1, len(simulated_ride))
        simulated_ride['accel_y'] += np.random.normal(0, 0.1, len(simulated_ride))
        simulated_ride['accel_z'] += np.random.normal(0, 0.1, len(simulated_ride))
        
        # Extract features
        magnitude = np.sqrt(simulated_ride['accel_x']**2 + simulated_ride['accel_y']**2 + simulated_ride['accel_z']**2)
        features = [
            magnitude.mean(), magnitude.std(), magnitude.max(),
            simulated_ride['accel_x'].mean(), simulated_ride['accel_x'].std(),
            simulated_ride['accel_y'].mean(), simulated_ride['accel_y'].std(),
            simulated_ride['accel_z'].mean(), simulated_ride['accel_z'].std()
        ]
        training_features.append(features)
    
    # Train models
    X = np.array(training_features)
    X_scaled = scaler.fit_transform(X)
    anomaly_model.fit(X_scaled)
    
    # Save models
    models_dir = os.path.join(os.path.dirname(__file__), 'models')
    os.makedirs(models_dir, exist_ok=True)
    joblib.dump(anomaly_model, os.path.join(models_dir, 'anomaly_detector.pkl'))
    joblib.dump(scaler, os.path.join(models_dir, 'scaler.pkl'))
    print("Saved anomaly_detector.pkl and scaler.pkl")

def generate_failure_predictor():
    """Generate failure_predictor.pkl"""
    print("Generating Failure Predictor...")
    
    # Create synthetic failure prediction data
    np.random.seed(42)
    n_samples = 1000
    
    # Features: vibration stats, operating hours, temperature, etc.
    features = []
    labels = []
    
    for i in range(n_samples):
        # Normal operation (70%)
        if i < 700:
            vibration_level = np.random.normal(1.0, 0.2)
            operating_hours = np.random.uniform(0, 8000)
            temperature = np.random.normal(75, 10)
            failure_risk = 0  # No failure
        # Early warning (20%)
        elif i < 900:
            vibration_level = np.random.normal(2.0, 0.3)
            operating_hours = np.random.uniform(6000, 12000)
            temperature = np.random.normal(85, 15)
            failure_risk = 1  # Early warning
        # Critical (10%)
        else:
            vibration_level = np.random.normal(3.5, 0.5)
            operating_hours = np.random.uniform(10000, 15000)
            temperature = np.random.normal(95, 20)
            failure_risk = 2  # Critical
        
        features.append([vibration_level, operating_hours, temperature])
        labels.append(failure_risk)
    
    # Train classifier
    X = np.array(features)
    y = np.array(labels)
    
    classifier = RandomForestClassifier(n_estimators=100, random_state=42)
    classifier.fit(X, y)
    
    # Save model
    models_dir = os.path.join(os.path.dirname(__file__), 'models')
    os.makedirs(models_dir, exist_ok=True)
    joblib.dump(classifier, os.path.join(models_dir, 'failure_predictor.pkl'))
    print("Saved failure_predictor.pkl")

def main():
    """Generate all required models"""
    print("Generating All ML Models for Agentic Maintenance Assistant")
    print("=" * 60)
    
    # Check if vibration data exists
    if not os.path.exists('vibration_data.csv'):
        print("ERROR: vibration_data.csv not found!")
        return
    
    # Generate models
    generate_anomaly_detector()
    generate_failure_predictor()
    
    print("\nAll models generated successfully!")
    print("Models created:")
    models_dir = os.path.join(os.path.dirname(__file__), 'models')
    print(f"  - {os.path.join(models_dir, 'anomaly_detector.pkl')}")
    print(f"  - {os.path.join(models_dir, 'scaler.pkl')}")
    print(f"  - {os.path.join(models_dir, 'failure_predictor.pkl')}")
    print("\nLSTM models should be generated by running lstm_fault_classifier.py")

if __name__ == "__main__":
    main()